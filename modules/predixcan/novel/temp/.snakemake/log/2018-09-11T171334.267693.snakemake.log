Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	clump_all
	1	clump_two
	2

rule clump_two:
    input: genie_clump/all2/all2ld_from_1kg.eur.biallele.snps.maf0.01/SPINE_BMD.gwas.sumstats.clumped, /hpc/users/xrajagv01/wen_gwas_files/SPINE_BMD.gwas.sumstats
    output: genie_clump/all2/all2ld_from_1kg.eur.biallele.snps.maf0.01/SPINE_BMD.gwas.sumstats.clumped.formatted
    jobid: 1
    wildcards: wcard=SPINE_BMD.gwas.sumstats

Finished job 1.
1 of 2 steps (50%) done

localrule clump_all:
    input: genie_clump/all2/all2ld_from_1kg.eur.biallele.snps.maf0.01/SPINE_BMD.gwas.sumstats.clumped, genie_clump/all2/all2ld_from_1kg.eur.biallele.snps.maf0.01/SPINE_BMD.gwas.sumstats.clumped.formatted
    jobid: 0

Finished job 0.
2 of 2 steps (100%) done
Complete log: /sc/orga/projects/va-biobank/Veera/genie/modules/predixcan/novel/temp/.snakemake/log/2018-09-11T171334.267693.snakemake.log
